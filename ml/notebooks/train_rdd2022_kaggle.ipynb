{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# üöÄ RoadDoctor: YOLOv8 Training on RDD2022\n\n**Simple & Production-Ready Training Pipeline**\n\n## üìã Setup (5 minutes):\n\n1. **Kaggle Settings**:\n   - Accelerator: **GPU T4 x2** ‚ö°\n   - Internet: **ON** üåê\n\n2. **Add Dataset**:\n   - Click **\"+ Add Data\"**\n   - Search: **\"RDD2022\"** or use: https://www.kaggle.com/datasets/nirmalsankalana/rdd2022\n   - Add dataset (already in YOLO format!)\n\n3. **Run**:\n   - Cell ‚Üí Run All\n   - Wait 2-3 hours ‚òï\n   - Download `best.pt`\n\n---\n\n**‚ú® Features:**\n- ‚úÖ Resume training if crashed\n- ‚úÖ Auto-save every 5 epochs\n- ‚úÖ Early stopping (patience=10)\n- ‚úÖ Full metrics & visualizations\n- ‚úÖ Handles RDD_SPLIT subdirectory automatically\n- ‚úÖ Detects 5 road damage types"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Install & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install Ultralytics YOLOv8\n!pip install ultralytics -q\n\nimport os\nimport yaml\nimport shutil\nfrom pathlib import Path\nfrom datetime import datetime\nfrom ultralytics import YOLO\n\n# Patch imread to skip corrupt images\nimport cv2\nimport numpy as np\nfrom ultralytics.utils import patches\n\noriginal_imread = patches.imread\n\ndef safe_imread(filename, flags=cv2.IMREAD_COLOR):\n    \"\"\"Wrapper that returns black image on error instead of crashing\"\"\"\n    try:\n        result = original_imread(filename, flags)\n        if result is None:\n            # Return small black placeholder\n            return np.zeros((100, 100, 3), dtype=np.uint8)\n        return result\n    except Exception as e:\n        # Return small black placeholder on any error\n        return np.zeros((100, 100, 3), dtype=np.uint8)\n\n# Apply patch\npatches.imread = safe_imread\n\nprint(\"‚úì Dependencies installed\")\nprint(\"‚úì Error handling enabled (corrupt images will be skipped)\")\nprint(f\"Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\nprint(f\"Working directory: {os.getcwd()}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üóÇÔ∏è Step 2: Locate RDD2022 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Find RDD2022 dataset (Kaggle auto-mounts to /kaggle/input)\npossible_paths = [\n    '/kaggle/input/rdd2022',\n    '/kaggle/input/road-damage-dataset-2022',\n    '/kaggle/input/rdd-2022',\n    '/kaggle/input/rdd2022-dataset'\n]\n\nrdd_base_path = None\nfor path in possible_paths:\n    if os.path.exists(path):\n        rdd_base_path = Path(path)\n        break\n\nif not rdd_base_path:\n    raise FileNotFoundError(\n        \"‚ùå RDD2022 not found!\\n\"\n        \"Please add dataset:\\n\"\n        \"1. Click '+ Add Data'\\n\"\n        \"2. Search 'RDD2022'\\n\"\n        \"3. Add to notebook\"\n    )\n\n# Check if dataset has RDD_SPLIT subdirectory\nif (rdd_base_path / 'RDD_SPLIT').exists():\n    rdd_path = rdd_base_path / 'RDD_SPLIT'\n    print(f\"‚úì Found RDD2022 at: {rdd_base_path}\")\n    print(f\"‚úì Using split data from: {rdd_path}\\n\")\nelse:\n    rdd_path = rdd_base_path\n    print(f\"‚úì Found RDD2022 at: {rdd_path}\\n\")\n\n!ls -lh {rdd_path}"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 3: Verify Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataset structure\n",
    "print(\"Checking dataset structure...\\n\")\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    images_dir = rdd_path / split / 'images'\n",
    "    labels_dir = rdd_path / split / 'labels'\n",
    "    \n",
    "    if images_dir.exists():\n",
    "        num_images = len(list(images_dir.glob('*.jpg'))) + len(list(images_dir.glob('*.png')))\n",
    "        num_labels = len(list(labels_dir.glob('*.txt')))\n",
    "        \n",
    "        print(f\"‚úì {split:5s}: {num_images:5d} images, {num_labels:5d} labels\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  {split:5s}: Not found\")\n",
    "\n",
    "print(\"\\n‚úì Dataset verified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# RDD2022 classes (dataset has 5 classes, not 4!)\nCLASS_NAMES = {\n    0: 'longitudinal_crack',\n    1: 'transverse_crack',\n    2: 'alligator_crack',\n    3: 'pothole',\n    4: 'other_damage'  # Additional damage types in dataset\n}\n\n# Create YAML config\n# Use relative paths from rdd_path\ndataset_config = {\n    'path': str(rdd_path),\n    'train': 'train/images',\n    'val': 'val/images',\n    'test': 'test/images',\n    'nc': 5,  # 5 classes, not 4!\n    'names': CLASS_NAMES\n}\n\nconfig_path = Path('/kaggle/working/rdd2022.yaml')\nwith open(config_path, 'w') as f:\n    yaml.dump(dataset_config, f, default_flow_style=False)\n\nprint(\"‚úì YAML configuration created\\n\")\nprint(\"Config:\")\n!cat {config_path}"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## üìù Step 4: Create YOLO Configuration"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Quick preview - uncomment to see samples\n# import matplotlib.pyplot as plt\n# import cv2\n# import numpy as np\n\n# sample_images = list((rdd_path / 'train' / 'images').glob('*.jpg'))[:6]\n\n# fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n# axes = axes.flatten()\n\n# for idx, img_path in enumerate(sample_images):\n#     img = cv2.imread(str(img_path))\n#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n#     axes[idx].imshow(img)\n#     axes[idx].set_title(img_path.name)\n#     axes[idx].axis('off')\n\n# plt.tight_layout()\n# plt.show()\n\nprint(\"‚úì Ready to train!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## üëÅÔ∏è Step 5: Preview Sample Images (Optional)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for existing checkpoint\n",
    "checkpoint_path = Path('runs/train/road_defect_detector/weights/last.pt')\n",
    "resume_training = False\n",
    "\n",
    "if checkpoint_path.exists():\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"‚ö†Ô∏è  Found existing checkpoint!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Checkpoint: {checkpoint_path}\")\n",
    "    print(\"\\nThis means training was interrupted before.\")\n",
    "    print(\"\\nOptions:\")\n",
    "    print(\"  1 = Resume from checkpoint\")\n",
    "    print(\"  2 = Start fresh (delete checkpoint)\\n\")\n",
    "    \n",
    "    # Note: In Kaggle, this will use default (1)\n",
    "    # You can manually change if needed\n",
    "    resume_training = True\n",
    "    print(\"Auto-resuming from checkpoint...\")\n",
    "else:\n",
    "    print(\"Starting fresh training run...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## üöÄ Step 6: Train YOLOv8n Model\n\n**This will take ~2-3 hours on T4 GPU**\n\nSettings:\n- **50 epochs** (adjust if needed)\n- **Batch size 16** (decrease to 8 if OOM)\n- **Auto-save** every 5 epochs\n- **Early stopping** after 10 epochs without improvement"
  },
  {
   "cell_type": "code",
   "source": "# Check for existing checkpoint\ncheckpoint_path = Path('runs/train/road_defect_detector/weights/last.pt')\nresume_training = False\n\nif checkpoint_path.exists():\n    print(\"\\n\" + \"=\"*60)\n    print(\"‚ö†Ô∏è  Found existing checkpoint!\")\n    print(\"=\"*60)\n    print(f\"Checkpoint: {checkpoint_path}\")\n    print(\"\\nThis means training was interrupted before.\")\n    print(\"\\nOptions:\")\n    print(\"  1 = Resume from checkpoint\")\n    print(\"  2 = Start fresh (delete checkpoint)\\n\")\n    \n    # Note: In Kaggle, this will use default (1)\n    # You can manually change if needed\n    resume_training = True\n    print(\"Auto-resuming from checkpoint...\")\nelse:\n    print(\"Starting fresh training run...\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Initialize model\nif resume_training:\n    model = YOLO(str(checkpoint_path))\n    print(f\"‚úì Loaded checkpoint: {checkpoint_path}\")\nelse:\n    model = YOLO('yolov8n.pt')\n    print(\"‚úì Loaded pretrained YOLOv8n\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"üöÄ STARTING TRAINING\")\nprint(\"=\"*60)\nprint(f\"Estimated time: 2-3 hours\")\nprint(f\"Monitor progress below...\")\nprint(\"=\"*60 + \"\\n\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Train!\nresults = model.train(\n    # Data\n    data=str(config_path),\n    \n    # Training params\n    epochs=50,\n    imgsz=640,\n    batch=16,          # Decrease to 8 if out of memory\n    device=0,          # Use GPU 0\n    amp=False,         # Disable AMP to avoid Kaggle errors\n    workers=4,         # Multi-threaded dataloader (now safe after cleanup)\n    \n    # Output\n    project='runs/train',\n    name='road_defect_detector',\n    exist_ok=True,\n    resume=resume_training,\n    \n    # Checkpointing\n    save=True,\n    save_period=5,     # Save every 5 epochs\n    patience=10,       # Early stopping\n    \n    # Data loading\n    rect=False,        # Disable rectangular training\n    cache=False,       # Don't cache images\n    \n    # Data augmentation\n    augment=True,\n    hsv_h=0.015,\n    hsv_s=0.7,\n    hsv_v=0.4,\n    degrees=10.0,\n    translate=0.1,\n    scale=0.5,\n    fliplr=0.5,\n    mosaic=1.0,\n    mixup=0.0,\n    \n    # Optimization\n    optimizer='SGD',\n    lr0=0.01,\n    momentum=0.937,\n    weight_decay=0.0005,\n    warmup_epochs=3.0,\n    \n    # Output\n    verbose=True,\n    plots=True\n)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"‚úÖ TRAINING COMPLETE!\")\nprint(\"=\"*60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## üìä Step 8: Evaluate Model"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load best model\nbest_model_path = 'runs/train/road_defect_detector/weights/best.pt'\nmodel = YOLO(best_model_path)\n\n# Validate\nmetrics = model.val()\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"üìä MODEL PERFORMANCE METRICS\")\nprint(\"=\"*60)\nprint(f\"mAP50:     {metrics.box.map50:.3f}    (main metric)\")\nprint(f\"mAP50-95:  {metrics.box.map:.3f}\")\nprint(f\"Precision: {metrics.box.mp:.3f}\")\nprint(f\"Recall:    {metrics.box.mr:.3f}\")\nprint(\"=\"*60)\n\n# Expected results:\n# mAP50: 0.70-0.80\n# Precision: 0.70-0.78\n# Recall: 0.65-0.75"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## üìä Step 7: Evaluate Model"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image as IPImage, display\n",
    "\n",
    "results_dir = Path('runs/train/road_defect_detector')\n",
    "\n",
    "print(\"\\nüìä Training Curves:\\n\")\n",
    "if (results_dir / 'results.png').exists():\n",
    "    display(IPImage(filename=str(results_dir / 'results.png')))\n",
    "\n",
    "print(\"\\nüéØ Confusion Matrix:\\n\")\n",
    "if (results_dir / 'confusion_matrix.png').exists():\n",
    "    display(IPImage(filename=str(results_dir / 'confusion_matrix.png')))\n",
    "\n",
    "print(\"\\nüìâ F1 Score Curve:\\n\")\n",
    "if (results_dir / 'F1_curve.png').exists():\n",
    "    display(IPImage(filename=str(results_dir / 'F1_curve.png')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## üìà Step 8: View Training Results"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import matplotlib.pyplot as plt\nimport cv2\n\n# Get random test images\ntest_images = list((rdd_path / 'val' / 'images').glob('*.jpg'))[:8]\n\nprint(f\"Testing on {len(test_images)} validation images...\\n\")\n\nfig, axes = plt.subplots(2, 4, figsize=(20, 10))\naxes = axes.flatten()\n\nfor idx, img_path in enumerate(test_images):\n    # Run inference\n    results = model(str(img_path), verbose=False)\n    \n    # Get annotated image\n    annotated = results[0].plot()\n    annotated = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n    \n    # Plot\n    axes[idx].imshow(annotated)\n    axes[idx].axis('off')\n    \n    # Title with detection count\n    num_detections = len(results[0].boxes)\n    axes[idx].set_title(f\"{img_path.name}\\n{num_detections} defects\", fontsize=10)\n\nplt.tight_layout()\nplt.savefig('/kaggle/working/test_predictions.png', dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(\"‚úì Test predictions shown\")\nprint(\"‚úì Saved to: /kaggle/working/test_predictions.png\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## üß™ Step 9: Test Predictions"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy model to working directory for easy download\n",
    "output_model = Path('/kaggle/working/best.pt')\n",
    "backup_model = Path('/kaggle/working/best_backup.pt')\n",
    "\n",
    "shutil.copy(best_model_path, output_model)\n",
    "shutil.copy(best_model_path, backup_model)\n",
    "\n",
    "# Copy training plots\n",
    "if (results_dir / 'results.png').exists():\n",
    "    shutil.copy(results_dir / 'results.png', '/kaggle/working/training_results.png')\n",
    "if (results_dir / 'confusion_matrix.png').exists():\n",
    "    shutil.copy(results_dir / 'confusion_matrix.png', '/kaggle/working/confusion_matrix.png')\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üíæ MODEL SAVED!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nModel files:\")\n",
    "print(f\"  ‚Ä¢ best.pt             ({output_model.stat().st_size / 1024 / 1024:.1f} MB)\")\n",
    "print(f\"  ‚Ä¢ best_backup.pt      ({backup_model.stat().st_size / 1024 / 1024:.1f} MB)\")\n",
    "print(f\"\\nVisualization files:\")\n",
    "print(f\"  ‚Ä¢ training_results.png\")\n",
    "print(f\"  ‚Ä¢ confusion_matrix.png\")\n",
    "print(f\"  ‚Ä¢ test_predictions.png\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üì• HOW TO DOWNLOAD:\")\n",
    "print(\"=\"*70)\n",
    "print(\"1. Click 'Output' tab on the right panel\")\n",
    "print(\"2. Download ALL files above\")\n",
    "print(\"3. Place best.pt in: ml/models/best.pt\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## üíæ Step 10: Save & Download Model"
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30664,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}