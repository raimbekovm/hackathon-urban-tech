# ğŸš€ RoadDoctor - Development Branch

> **Live Demo:** [https://raimbekovm.github.io/hackathon-urban-tech/](https://raimbekovm.github.io/hackathon-urban-tech/)
> **Main Branch:** [Production Frontend](https://github.com/raimbekovm/hackathon-urban-tech/tree/main)

This is the **development branch** containing the complete RoadDoctor system: ML pipeline, training notebooks, datasets, and frontend application.

## ğŸ“‹ What's in This Branch

This branch contains the **full development environment** with:

âœ… **Complete ML Pipeline** - Detection, analysis, and data processing
âœ… **Frontend Application** - Interactive dashboard with all visualization modes
âœ… **Training Notebooks** - Kaggle notebooks for model fine-tuning
âœ… **Custom Datasets** - Annotated Bishkek road images
âœ… **Documentation** - Setup guides and API references

## ğŸ“ Directory Structure

```
dev/
â”œâ”€â”€ frontend/                    # Web dashboard application
â”‚   â”œâ”€â”€ index.html              # Main page
â”‚   â”œâ”€â”€ app.js                  # Application logic
â”‚   â””â”€â”€ README.md               # Frontend-specific docs
â”‚
â”œâ”€â”€ ml/                         # Machine learning pipeline
â”‚   â”œâ”€â”€ data/                   # Training and test data
â”‚   â”‚   â”œâ”€â”€ bishkek_roads/     # 45 real street images
â”‚   â”‚   â”œâ”€â”€ portfolio_samples/  # 9 annotated examples (showcase)
â”‚   â”‚   â”‚   â”œâ”€â”€ images/        # Sample photos
â”‚   â”‚   â”‚   â”œâ”€â”€ labels/        # YOLO annotations
â”‚   â”‚   â”‚   â””â”€â”€ README.md      # Annotation documentation
â”‚   â”‚   â””â”€â”€ urban_tech/        # Full training dataset
â”‚   â”‚       â”œâ”€â”€ train/         # Training images & labels
â”‚   â”‚       â”œâ”€â”€ test/          # Test images & labels
â”‚   â”‚       â””â”€â”€ data.yaml      # Dataset configuration
â”‚   â”‚
â”‚   â”œâ”€â”€ notebooks/             # Jupyter/Kaggle notebooks
â”‚   â”‚   â””â”€â”€ train_rdd2022_kaggle.ipynb  # YOLOv8 training
â”‚   â”‚
â”‚   â”œâ”€â”€ output/                # Generated detection results
â”‚   â”‚   â”œâ”€â”€ defects.csv       # All defects with coordinates
â”‚   â”‚   â”œâ”€â”€ worst_roads.json  # Priority-ranked roads
â”‚   â”‚   â”œâ”€â”€ heatmap.json      # Heatmap intensity data
â”‚   â”‚   â”œâ”€â”€ stats.json        # Statistical summaries
â”‚   â”‚   â””â”€â”€ districts.json    # District aggregations
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                # Helper functions
â”‚   â”‚   â”œâ”€â”€ scoring.py        # Severity & priority algorithms
â”‚   â”‚   â””â”€â”€ visualization.py  # Chart generation
â”‚   â”‚
â”‚   â”œâ”€â”€ process_real_data.py  # Main ML pipeline
â”‚   â”œâ”€â”€ get_street_names.py   # Reverse geocoding script
â”‚   â””â”€â”€ README.md             # ML documentation
â”‚
â””â”€â”€ README.md                  # This file
```

## ğŸš€ Quick Start

### Prerequisites
```bash
Python 3.8+
pip
Git
```

### 1. Clone and Setup
```bash
# Clone repository and switch to dev branch
git clone https://github.com/raimbekovm/hackathon-urban-tech.git
cd hackathon-urban-tech
git checkout dev

# Set up ML environment
cd ml
python3 -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 2. Run ML Pipeline
```bash
# Process road images and detect defects
python process_real_data.py

# Add real street names via geocoding (optional)
python get_street_names.py
```

This generates output files in `ml/output/`:
- `defects.csv` - All detected defects
- `worst_roads.json` - Priority-ranked roads
- `heatmap.json` - Heatmap data
- `stats.json` - Statistics
- `districts.json` - District summaries

### 3. Launch Frontend
```bash
# Go back to root and start server
cd ..
python3 -m http.server 8000

# Open in browser
open http://localhost:8000/frontend/
```

## ğŸ¯ Development Workflow

### Working with Datasets

#### Portfolio Samples (9 images)
Example annotations for showcase:
```bash
ls ml/data/portfolio_samples/images/
# Screenshot_001.jpg ... Screenshot_009.jpg

ls ml/data/portfolio_samples/labels/
# Screenshot_001.txt ... Screenshot_009.txt
```

#### Full Training Dataset
Complete dataset for model training:
```bash
# View dataset structure
cat ml/data/urban_tech/data.yaml

# Training data
ls ml/data/urban_tech/train/images/
ls ml/data/urban_tech/train/labels/
```

### Training Model on Kaggle

1. Upload `ml/notebooks/train_rdd2022_kaggle.ipynb` to Kaggle
2. Enable GPU accelerator
3. Update dataset paths
4. Run all cells (50 epochs, ~2 hours)
5. Download trained weights

### Processing New Images

Add new road images to `ml/data/bishkek_roads/`:
```bash
# Add your images
cp /path/to/images/*.jpg ml/data/bishkek_roads/

# Run detection
cd ml
python process_real_data.py

# Update with street names
python get_street_names.py
```

### Updating Frontend Data

After running ML pipeline, data is automatically available:
```bash
# Frontend reads from ml/output/
frontend/app.js â†’ loads ../ml/output/defects.csv
frontend/app.js â†’ loads ../ml/output/worst_roads.json
# etc.
```

## ğŸ› ï¸ Technology Stack

### ML Pipeline
- **YOLOv8n** - Object detection (Ultralytics)
- **OpenCV** - Image processing
- **Pandas** - Data manipulation
- **Roboflow** - Dataset annotation
- **Nominatim** - Reverse geocoding (OpenStreetMap)

### Frontend
- **Leaflet.js** - Interactive maps
- **Leaflet.heat** - Heatmap plugin
- **Chart.js** - Data visualization
- **Vanilla JS** - No frameworks

## ğŸ“Š Data Annotations

### Annotation Format
YOLO format (.txt files):
```
class_id x_center y_center width height
```

Example:
```
0 0.673745 0.704904 0.258170 0.353179  # longitudinal_crack
3 0.486070 0.422343 0.084577 0.179837  # pothole
```

### Classes
- `0` - longitudinal_crack (ĞŸÑ€Ğ¾Ğ´Ğ¾Ğ»ÑŒĞ½Ğ°Ñ Ñ‚Ñ€ĞµÑ‰Ğ¸Ğ½Ğ°)
- `1` - transverse_crack (ĞŸĞ¾Ğ¿ĞµÑ€ĞµÑ‡Ğ½Ğ°Ñ Ñ‚Ñ€ĞµÑ‰Ğ¸Ğ½Ğ°)
- `2` - alligator_crack (Ğ¡ĞµÑ‚ĞºĞ° Ñ‚Ñ€ĞµÑ‰Ğ¸Ğ½)
- `3` - pothole (Ğ¯Ğ¼Ğ°)

### Annotation Statistics
- **Total images**: 45
- **Training set**: 39 images
- **Test set**: 6 images
- **Total objects**: 172
  - Longitudinal cracks: 67
  - Transverse cracks: 11
  - Alligator cracks: 63
  - Potholes: 31

See `ml/data/portfolio_samples/ANNOTATION_EXAMPLES.md` for details.

## ğŸ”§ Configuration

### Dataset Config (`ml/data/urban_tech/data.yaml`)
```yaml
path: /kaggle/working/urban_tech
train: train/images
val: valid/images
test: test/images

names:
  0: longitudinal_crack
  1: transverse_crack
  2: alligator_crack
  3: pothole
```

### Model Training Parameters
```python
model = YOLO('yolov8n.pt')
results = model.train(
    data='data.yaml',
    epochs=50,
    imgsz=640,
    batch=16,
    name='road_defects'
)
```

## ğŸ“ˆ ML Pipeline Workflow

1. **Image Collection** â†’ Screenshots from Google Maps Street View
2. **Annotation** â†’ Manual labeling in Roboflow (YOLO format)
3. **Training** â†’ YOLOv8 fine-tuning on Kaggle GPU
4. **Inference** â†’ Detect defects in new images
5. **Post-processing** â†’ Severity scoring, priority ranking
6. **Geocoding** â†’ Add street names via Nominatim API
7. **Export** â†’ Generate JSON/CSV for frontend

## ğŸ§ª Testing

### Test ML Pipeline
```bash
cd ml
python -c "from utils.scoring import calculate_severity; print(calculate_severity(100, 80, 'pothole', 0.95))"
# Expected: ~8.5 (high severity)
```

### Test Frontend Locally
```bash
python3 -m http.server 8000
open http://localhost:8000/frontend/
```

## ğŸš€ Deployment

### Deploy to GitHub Pages
```bash
# Merge dev to main
git checkout main
git merge dev

# Push to trigger GitHub Actions
git push origin main

# GitHub Actions automatically deploys to gh-pages
```

### Manual Deployment
```bash
# Use provided script
./update-gh-pages.sh
```

## ğŸ“ Development Guidelines

### Adding New Features

1. **Create feature branch**
   ```bash
   git checkout -b feature/new-visualization
   ```

2. **Make changes**
   - Update ML pipeline or frontend
   - Test locally
   - Update documentation

3. **Commit and push**
   ```bash
   git add .
   git commit -m "feat: add new visualization mode"
   git push origin feature/new-visualization
   ```

4. **Create pull request** to dev branch

### Code Style

- **Python**: PEP 8
- **JavaScript**: ESLint recommended
- **Commits**: Conventional Commits format
  - `feat:` - New features
  - `fix:` - Bug fixes
  - `docs:` - Documentation
  - `chore:` - Maintenance

## ğŸ› Troubleshooting

### Common Issues

**Q: ML pipeline shows "No defects detected"**
A: Check if images are in correct folder and model weights are downloaded

**Q: Frontend shows 404 errors**
A: Verify relative paths in `app.js` are correct (`../ml/output/`)

**Q: Geocoding is slow**
A: Nominatim has 1 request/second rate limit - this is normal

**Q: Training fails on Kaggle**
A: Ensure dataset paths match Kaggle file structure

See `DEBUG.md` for detailed troubleshooting.

## ğŸ‘¥ Team & Contributors

**Urban Tech Hackathon 2025**
- ML Engineering & Dataset Annotation
- Frontend Development & UI/UX
- Data Science & Analytics
- Project Management

## ğŸ“„ License

MIT License - Developed for Urban Tech Hackathon 2025

## ğŸ”— Related Links

- [Live Demo](https://raimbekovm.github.io/hackathon-urban-tech/)
- [Main Branch (Production)](https://github.com/raimbekovm/hackathon-urban-tech/tree/main)
- [GitHub Pages Branch](https://github.com/raimbekovm/hackathon-urban-tech/tree/gh-pages)
- [YOLOv8 Documentation](https://docs.ultralytics.com/)
- [RDD2022 Dataset](https://github.com/sekilab/RoadDamageDetector)

---

**Development Status:** Active
**Last Updated:** December 2025
**Built with â¤ï¸ for making Bishkek roads safer**
